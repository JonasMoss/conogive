newdata = ltm::WIRS
object = latcon(newdata, fm = "ml")
object
object$lambda
object$lambda %*% t(object$lambda) + diag(sigma^2)
object$lambda %*% t(object$lambda) + diag(object$sigma^2)
psych::fa
?psych::fa
?do.call
devtools::load_all(".")
newdata = ltm::WIRS
object = latcon(newdata, fm = "ml")
devtools::load_all(".")
newdata = ltm::WIRS
object = latcon(newdata, fm = "ml")
devtools::load_all(".")
newdata = ltm::WIRS
object = latcon(newdata, fm = "ml")
devtools::load_all(".")
newdata = ltm::WIRS
object = latcon(newdata, fm = "ml")
devtools::load_all(".")
newdata = ltm::WIRS
object = latcon(newdata, fm = "ml")
object
newdata = ltm::WIRS
object = latcon(newdata, fm = "minres")
object
newdata = ltm::WIRS
object = latcon(newdata, fm = "ml")
y = predict(object, newdata)
ordinal_omega(object, weights = "optimal")
mod = lm(z ~ y)
plot(y, z)
lines(sort(y), coef(mod)[1] + coef(mod)[2]*sort(y))
summary(mod)
?psych::scoreIrt
install.packages("MIRT")
install.packages("mirtT")
install.packages("mirt")
?mirt::mirt()
mod = lm(z ~ y)
plot(y, z)
lines(sort(y), coef(mod)[1] + coef(mod)[2]*sort(y))
ltm::Abortion
newdata = ltm::abortion
object = latcon(newdata, fm = "ml")
y = predict(object, newdata)
ordinal_omega(object, weights = "optimal")
z = psych::scoreIrt(psych::irt.fa(newdata), newdata)[, 1]
#library("ltm")
#z = factor.scores(ltm::ltm(ltm::WIRS ~ z1), ltm::WIRS)$score.dat$z1
mod = lm(z ~ y)
plot(y, z)
lines(sort(y), coef(mod)[1] + coef(mod)[2]*sort(y))
newdata = ltm::abortion
object = latcon(newdata, fm = "ml")
y = predict(object, newdata)
ordinal_omega(object, weights = "optimal")
ordinal_omega(object, weights = "optimal", limit = TRUE)
psych::irt.fa(newdata)
?psych::irt.fa
devtools::load_all(".")
devtools::load_all(".")
devtools::load_all(".")
devtools::load_all(".")
devtools::load_all(".")
agreeableness = psychTools::bfi[c("A1", "A2", "A3", "A4", "A5")]
agreeableness[, "A1"] = 7 - agreeableness[, "A1"] # Reverse-coded item.
object = latcon(agreeableness)
ordinal_alpha(object) # 0.6267724
ordinal_omega(object, weights = "equal") # 0.6394087
devtools::load_all(".")
xi_sample
y
y = mtcars[, c("vs", "am", "gear", "carb")]
msg = "Smaller number of categories than length of cuts."
expect_error(xi_sample(y, cuts[[1]]), regexp = msg)
expect_equal(dim(xi_sample(ordered_y(y), cuts)), c(k, k))
y = mtcars[, c("vs", "am", "gear", "carb")]
cuts = list(qnorm(seq(0, 1, length.out = 3)),
qnorm(seq(0, 1, length.out = 3)),
qnorm(seq(0, 1, length.out = 4)),
qnorm(seq(0, 1, length.out = 9)))
rho = cor(y)
k = ncol(y)
test_that("trim_vector accepts only numeric vectors with no NAs", {
expect_error(trim_vector("a"))
expect_error(trim_vector(lm))
expect_error(trim_vector(matrix(1, 2, 2)))
expect_error(trim_vector(c(1,NA)))
})
test_that("trim_vector removes all infinities and appends/prepends", {
vec = c(1, Inf, -Inf, 2)
expect_equal(trim_vector(vec)[1], -Inf)
expect_equal(tail(trim_vector(vec),1), Inf)
expect_equal(trim_vector(vec)[2], 1)
expect_equal(trim_vector(vec)[3], 2)
})
test_that("massage_cuts accepts appropriate input and returns the right values", {
expect_error(massage_cuts(NULL, "a"))
expect_error(massage_cuts(NULL, 5), "list")
expect_type(massage_cuts(cuts, 5), "list")
expect_equal(length(massage_cuts(cuts[[1]])), 1)
})
test_that("xi_theoretical works", {
rho_ = rho
rho_[1, 1] = NA
expect_equal(dim(xi_theoretical(cuts, rho = rho)), c(k, k))
expect_error(xi_theoretical(cuts, rho = "a"))
expect_error(xi_theoretical(cuts, rho = rho_))
})
test_that("xi_sample works", {
msg = "Smaller number of categories than length of cuts."
expect_error(xi_sample(y, cuts[[1]]), regexp = msg)
expect_equal(dim(xi_sample(ordered_y(y), cuts)), c(k, k))
})
test_that("x_hat throws errors and returns the correct type", {
expect_error(x_hat(c("NA" ,1, 2), cuts[[1]]))
expect_type(x_hat(c(2 ,1, 2), cuts[[1]]), "double")
})
test_that("standardize-functions works", {
lambda = 1:3
sigma = 1:3
expect_error(standardize_lambda(c(NA ,1, 2)))
expect_error(standardize_sigma(c(NA ,1, 2)))
expect_equal(standardize_lambda(lambda, sigma),
standardize_sigma(lambda, sigma))
})
devtools::load_all(".")
latcon(list(lambda = rep(1, 3), sigma = rep(1, 3), cuts = c(-Inf, 0, Inf)))
devtools::load_all(".")
latcon(list(lambda = rep(1, 3), sigma = rep(1, 3), cuts = c(-Inf, 0, Inf)))
devtools::load_all(".")
latcon(list(lambda = rep(1, 3), sigma = rep(1, 3), cuts = c(-Inf, 0, Inf)))
data = list(lambda = rep(1, 3), sigma = rep(1, 3), cuts = c(-Inf, 0, Inf))
data
checkmate::assertNumeric(data$lambda)
k = length(data$lambda)
checkmate::assertNumeric(data$sigma, len = k)
cuts = massage_cuts(data$cuts, k)
checkmate::assertList(cuts, len = k)
lambda = standardize_lambda(data$lambda, data$sigma)
sigma = standardize_sigma(data$lambda, data$sigma)
object = list(rho = tcrossprod(lambda, lambda) + diag(sigma^2),
cuts = cuts,
lambda = lambda,
sigma = sigma,
xi_sample = xi_theoretical(cuts, rho),
n = Inf)
cuts
lambda
sigma
rho
xi_theoretical(cuts, rho)
cuts
rho
devtools::load_all(".")
list(lambda = rep(1, 3), sigma = rep(1, 3), cuts = c(-Inf, 0, Inf))
latcon(list(lambda = rep(1, 3), sigma = rep(1, 3), cuts = c(-Inf, 0, Inf)))
fit = latcon(list(lambda = rep(1, 3),
sigma = rep(1, 3),
cuts = c(-Inf, 0, Inf)))
ordinal_omega(fit)
fit = latcon(list(lambda = rep(1, 3),
sigma = rep(1, 3),
cuts = c(-Inf, 0, Inf)))
ordinal_omega(fit, limit = TRUE)
fit = latcon(list(lambda = rep(1, 10),
sigma = rep(1, 10),
cuts = c(-Inf, 0, Inf)))
ordinal_omega(fit, limit = TRUE)
fit = latcon(list(lambda = rep(1, 10),
sigma = rep(1, 10),
cuts = c(-Inf, 0, Inf)))
ordinal_omega(fit)
fit = latcon(list(lambda = rep(1, 10),
sigma = rep(1, 10),
cuts = qnorm(seq(0, 1, length.out = 3))
ordinal_omega(fit)
qnorm(seq(0, 1, length.out = 3)
)
fit = latcon(list(lambda = rep(1, 10),
sigma = rep(1, 10),
cuts = qnorm(seq(0, 1, length.out = 4)))
ordinal_omega(fit)
fit = latcon(list(lambda = rep(1, 10),
sigma = rep(1, 10),
cuts = qnorm(seq(0, 1, length.out = 4))))
ordinal_omega(fit)
f = Vectorize(function(k) {
fit = latcon(list(lambda = rep(1, 10),
sigma = rep(1, 10),
cuts = qnorm(seq(0, 1, length.out = k + 1))))
ordinal_omega(fit)
})
k = 2:30
plot(k, f(k))
f = Vectorize(function(k) {
fit = latcon(list(lambda = rep(1, 4),
sigma = rep(1, 4),
cuts = qnorm(seq(0, 1, length.out = k + 1))))
ordinal_omega(fit)
})
k = 2:30
plot(k, f(k))
y = mtcars[, c("vs", "am", "gear", "carb")]
cuts = list(qnorm(seq(0, 1, length.out = 3)),
qnorm(seq(0, 1, length.out = 3)),
qnorm(seq(0, 1, length.out = 4)),
qnorm(seq(0, 1, length.out = 9)))
rho = cor(y)
k = ncol(y)
xi_sample(y, cuts[[1]])
library("conogive")
xi_sample(y, cuts[[1]])
devtools::load_all(".")
xi_sample(y, cuts[[1]])
msg = "Smaller number of categories than length of cuts."
expect_error(xi_sample(y, cuts[[1]]), regexp = msg)
xi_sample(ordered_y(y)
)
xi_sample(ordered_y(y), cuts)
cuts
ordered_y
ordered_y(y)
y = ordered_y(y)
k = ncol(y)
n_categories = apply(y, 2, max, na.rm = TRUE)
cuts = massage_cuts(cuts, k)
lengths = sapply(cuts, length) - 1
assertthat::assert_that(sum(lengths - n_categories) >= 0,
msg = "Smaller number of categories than length of cuts.")
args = lapply(seq.int(k), function(i) x_hat(y[, i], cuts[[i]]))
xhats = do.call(what = cbind, args = args)
use = "complete.obs"
stats::cov(xhats, use = use)
xhats
k = ncol(y)
n_categories = apply(y, 2, max, na.rm = TRUE)
cuts = massage_cuts(cuts, k)
lengths = sapply(cuts, length) - 1
assertthat::assert_that(sum(lengths - n_categories) >= 0,
msg = "Smaller number of categories than length of cuts.")
args = lapply(seq.int(k), function(i) x_hat(y[, i], cuts[[i]]))
args
y
n_categories
cuts
lengths
y
x_hat
y
y[, 1]
args
x_hat(y[, 1], cuts[[1]]
)
cuts
)y
y
x_hat(y[, 1], cuts[[1]])
cuts
f = function(i) {
-(stats::dnorm(cuts[i + 1]) - stats::dnorm(cuts[i]))/
(stats::pnorm(cuts[i + 1]) - stats::pnorm(cuts[i]))
}
f(1)
cuts
cuts_ = cuts
f = function(i) {
-(stats::dnorm(cuts_[i + 1]) - stats::dnorm(cuts_[i]))/
(stats::pnorm(cuts_[i + 1]) - stats::pnorm(cuts_[i]))
}
cuts_ = cuts
f(1)
cuts_
cuts_ = cuts[[1]]
f(1)
f(0)
i = 0
stats::dnorm(cuts_[i + 1])
stats::dnorm(cuts_[i])
stats::dnorm(-Inf)
cuts_[0]
cuts
seq.int(k)
y
ordered_y(y)
y = mtcars[, c("vs", "am", "gear", "carb")]
cuts = list(qnorm(seq(0, 1, length.out = 3)),
qnorm(seq(0, 1, length.out = 3)),
qnorm(seq(0, 1, length.out = 4)),
qnorm(seq(0, 1, length.out = 9)))
rho = cor(y)
k = ncol(y)
y''
y
ordered(y)
oordered_y(y)
ordered_y = function(y) {
k = ncol(y)
y = data.frame(apply(data.frame(y), 2, as.factor))
for(i in seq.int(k)) levels(y[, i]) = seq.int(length(levels(y[, i])))
matrix(as.numeric(as.matrix(y)), ncol = k)
}
oordered_y(y)
devtools::load_all(".")
ordered_y(y)
y
k = ncol(y)
data.frame(apply(data.frame(y), 2, as.factor))
levels(data.frame(apply(data.frame(y), 2, as.factor)))
levels(apply(data.frame(y), 2, as.factor))
apply(data.frame(y), 2, as.factor)
psychTools::bfi[c("E1", "E2", "E3", "E4", "E5")]
y
devtools::load_all(".")
devtools::load_all(".")
devtools::load_all(".")
y = mtcars[, c("vs", "am", "gear", "carb")]
cuts = list(qnorm(seq(0, 1, length.out = 3)),
qnorm(seq(0, 1, length.out = 3)),
qnorm(seq(0, 1, length.out = 4)),
qnorm(seq(0, 1, length.out = 9)))
rho = cor(y)
k = ncol(y)
y
devtools::load_all(".")
devtools::load_all(".")
y = mtcars[, c("vs", "am", "gear", "carb")]
y[, 1] = 1 + y[, 1]
y[, 2] = 1 + y[, 2]
cuts = list(qnorm(seq(0, 1, length.out = 3)),
qnorm(seq(0, 1, length.out = 3)),
qnorm(seq(0, 1, length.out = 4)),
qnorm(seq(0, 1, length.out = 9)))
rho = cor(y)
k = ncol(y)
test_that("thurstone works on parallel models", {
lambda = rep(1, 4)
sigma = rep(1, 4)
expect_equal(thurstone(lambda, sigma), c(0.2, 0.2, 0.2, 0.2))
})
test_that("tr works", {
expect_equal(tr(rho), sum(diag(rho)))
})
test_that("trim_vector accepts only numeric vectors with no NAs", {
expect_error(trim_vector("a"))
expect_error(trim_vector(lm))
expect_error(trim_vector(matrix(1, 2, 2)))
expect_error(trim_vector(c(1,NA)))
})
test_that("trim_vector accepts only numeric vectors with no NAs", {
expect_error(trim_vector("a"))
expect_error(trim_vector(lm))
expect_error(trim_vector(matrix(1, 2, 2)))
expect_error(trim_vector(c(1,NA)))
})
test_that("trim_vector removes all infinities and appends/prepends", {
vec = c(1, Inf, -Inf, 2)
expect_equal(trim_vector(vec)[1], -Inf)
expect_equal(tail(trim_vector(vec),1), Inf)
expect_equal(trim_vector(vec)[2], 1)
expect_equal(trim_vector(vec)[3], 2)
})
test_that("massage_cuts accepts appropriate input and returns the right values", {
expect_error(massage_cuts(NULL, "a"))
expect_error(massage_cuts(NULL, 5), "list")
expect_type(massage_cuts(cuts, 5), "list")
expect_equal(length(massage_cuts(cuts[[1]])), 1)
})
test_that("xi_theoretical works", {
rho_ = rho
rho_[1, 1] = NA
expect_equal(dim(xi_theoretical(cuts, rho = rho)), c(k, k))
expect_error(xi_theoretical(cuts, rho = "a"))
expect_error(xi_theoretical(cuts, rho = rho_))
})
test_that("xi_sample works", {
msg = "Larger number of categories than length of cuts."
expect_error(xi_sample(y, cuts[[1]]), regexp = msg)
expect_equal(dim(xi_sample(y, cuts)), c(k, k))
})
test_that("x_hat throws errors and returns the correct type", {
expect_error(x_hat(c("NA" ,1, 2), cuts[[1]]))
expect_type(x_hat(c(2 ,1, 2), cuts[[1]]), "double")
})
test_that("standardize-functions works", {
lambda = 1:3
sigma = 1:3
expect_error(standardize_lambda(c(NA ,1, 2)))
expect_error(standardize_sigma(c(NA ,1, 2)))
expect_equal(standardize_lambda(lambda, sigma),
standardize_sigma(lambda, sigma))
})
devtools::load_all(".")
k = ncol(y)
n_categories = apply(y, 2, max, na.rm = TRUE)
cuts = massage_cuts(cuts, k)
lengths = sapply(cuts, length) - 1
assertthat::assert_that(sum(n_categories - lengths) >= 0,
msg = "Larger number of categories than length of cuts.")
args = lapply(seq.int(k), function(i) x_hat(y[, i], cuts[[i]]))
xhats = do.call(what = cbind, args = args)
stats::cov(xhats, use = use)
y
k = ncol(y)
n_categories = apply(y, 2, max, na.rm = TRUE)
cuts = massage_cuts(cuts, k)
lengths = sapply(cuts, length) - 1
assertthat::assert_that(sum(n_categories - lengths) >= 0,
msg = "Larger number of categories than length of cuts.")
args = lapply(seq.int(k), function(i) x_hat(y[, i], cuts[[i]]))
xhats = do.call(what = cbind, args = args)
xhats
cuts
y
cuts
ordered_y = function(y) {
k = ncol(y)
y = data.frame(apply(data.frame(y), 2, as.factor))
for(i in seq.int(k)) levels(y[, i]) = seq.int(length(levels(y[, i])))
matrix(as.numeric(as.matrix(y)), ncol = k)
}
ordered_y(y)
n_categories = apply(y, 2, max, na.rm = TRUE)
n_categories
devtools::load_all(".")
k = ncol(y)
n_categories = apply(y, 2, max, na.rm = TRUE)
cuts = massage_cuts(cuts, k)
lengths = sapply(cuts, length) - 1
assertthat::assert_that(sum(n_categories - lengths) <= 0,
msg = "Larger number of categories than length of cuts.")
args = lapply(seq.int(k), function(i) x_hat(y[, i], cuts[[i]]))
xhats = do.call(what = cbind, args = args)
stats::cov(xhats, use = use)
msg = "Larger number of categories than length of cuts."
expect_error(xi_sample(y, cuts[[1]]), regexp = msg)
dim(xi_sample(y, cuts))
y
y = mtcars[, c("vs", "am", "gear", "carb")]
y[, 1] = 1 + y[, 1]
y[, 2] = 1 + y[, 2]
y[, 3] = y[, 2] - 2
y
y = mtcars[, c("vs", "am", "gear", "carb")]
y[, 1] = 1 + y[, 1]
y[, 2] = 1 + y[, 2]
y[, 3] = y[, 3] - 2
y
devtools::load_all(".")
devtools::load_all(".")
?min
devtools::load_all(".")
extraversion = psychTools::bfi[c("E1", "E2", "E3", "E4", "E5")]
extraversion[, "E1"] = 7 - extraversion[, "E1"] # Reverse-coded item.
extraversion[, "E2"] = 7 - extraversion[, "E2"] # Reverse-coded item.
fit = conogive(extraversion)
options(buildtools.check=NULL)
Sys.which("make")
writeLines('PATH="${RTOOLS40_HOME}\usr\bin;${PATH}"', con = "~/.Renviron")
remotes::install_github("r-lib/pkgbuild")
remotes::install_github("r-lib/pkgbuild")
install_deps()
devtools::install_deps()
library(conogive)
install.packages("backports")
?devtools::check
devtools::check(cran = TRUE, incoming = TRUE)
.rversion
R.Version()
install.packages("rhub")
?rhub::check_on_solaris
rhub::check_on_solaris()
library(psychTools)
remove.packages("psychTools")
library(conogive)
rhub::check_on_solaris()
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(out.width='750px', dpi=200)
library("conogive")
extraversion = psychTools::bfi[c("E1", "E2", "E3", "E4", "E5")]
extraversion[, "E1"] = 7 - extraversion[, "E1"] # Reverse-coded item.
extraversion[, "E2"] = 7 - extraversion[, "E2"] # Reverse-coded item.
object = conogive(extraversion)
ordinal_r(object) # Observed reliability
r(object) # Theoretical reliability
library("conogive")
extraversion = psychTools::bfi[c("E1", "E2", "E3", "E4", "E5")]
extraversion[, "E1"] = 7 - extraversion[, "E1"] # Reverse-coded item.
extraversion[, "E2"] = 7 - extraversion[, "E2"] # Reverse-coded item.
object = conogive(extraversion)
ordinal_r(object) # Observed reliability
theoretical_ordinal_r(object) # Theoretical reliability
hist(predict(object, extraversion)) # Plot distribution of predictions.
a = seq(-0.85, 0, by = 0.01)
b = seq(0, 0.99, by = 0.01)
pdf("congeneric.pdf", height = 8, width = 8)
mar = c(5.1, 4.1, 4.1, 2.1)
par(mar = mar + c(0, 0.5, 0, 0))
plot(c(-sqrt(abs(a)),sqrt(abs(b))), sqrt(abs(c(a,b))), type = "l",
ylim = c(0, 1), lwd = 2, lty = 1, xlab = expression(lambda[2]),
ylab = expression(lambda[1]~and~sigma), cex.lab = 1.4, xlim = c(-1, 1))
lines(c(-sqrt(abs(a)),sqrt(abs(b))), sqrt(1 - c(a,b)^2), lwd = 2, lty = 2)
axis(side = 3, at = c(-sqrt(0.85)),
labels = expression(sqrt(0.85)))
axis(side = 3, at = c(sqrt(0.99)),
labels = expression(sqrt(0.99)))
legend("bottomleft", c(expression(lambda[1]), expression(sigma)),
lwd = c(2, 2), lty = c(1, 2), bty = "n", cex = 2)
dev.off()
